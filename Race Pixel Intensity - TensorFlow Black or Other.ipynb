{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ability of Artificial Intelligence to Identify Self-Reported Race in Chest X-Ray Using Pixel Intensity Counts\n",
    "## Tensorflow Feed Forward Network and Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Server specific Keras requirement\n",
    "\n",
    "import os\n",
    "import GPUtil\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "DEVICE_ID_LIST = GPUtil.getAvailable(order = 'memory', limit = 2,\n",
    "maxMemory = 0.5 )\n",
    "LIST_LENGTH = len(DEVICE_ID_LIST)\n",
    "if LIST_LENGTH == 0 :\n",
    "    raise ValueError(\"There are no available GPUs with the required limits listed in GPUtil.getAvailable()\")\n",
    "AVAIL_DEVICES = str(DEVICE_ID_LIST[0]) # grab first element from list\n",
    "#intentionally starting with 1 because we've added 0\n",
    "COUNT = 1\n",
    "while COUNT < LIST_LENGTH:\n",
    "    AVAIL_DEVICES += \",\" + str(DEVICE_ID_LIST[COUNT])\n",
    "    COUNT += 1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = AVAIL_DEVICES\n",
    "print('Device IDs (unmasked): ' + AVAIL_DEVICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Conv1D, Conv2D, MaxPool1D, MaxPooling2D, AveragePooling1D, Flatten, Dropout, BatchNormalization, LSTM, GRU, Softmax, RNN, SimpleRNN, LSTM, GRU\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam, Adamax, Ftrl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read from a csv\n",
    "freq_df = pd.read_csv('frequencies.csv', index_col=0, header=0)\n",
    "\n",
    "#get all race labels\n",
    "races = freq_df['race'].unique()\n",
    "\n",
    "#convert to percents\n",
    "#first make a copy of data\n",
    "#get just the numeric columns - removing 0 to remove all pure non-image black space often used in border to rotate the images\n",
    "freq_percent_df = freq_df.copy(deep=True).iloc[:, 1 : 257]\n",
    "\n",
    "#get just the numeric columns\n",
    "freq_percent_df_num = freq_percent_df.iloc[:, 0 : 255]\n",
    "\n",
    "#conversion to percents\n",
    "freq_percent_df_num = freq_percent_df_num.div(freq_df.sum(axis=1, numeric_only=True), axis=0)\n",
    "freq_percent_df[freq_percent_df_num.columns] = freq_percent_df_num\n",
    "\n",
    "\n",
    "#drop classes, for Black or white analysis uncomment line 21 and comment line 22\n",
    "#freq_percent_df2 = freq_percent_df.copy(deep=True)[freq_percent_df['race'].str.contains(\"asian|hispanic\")==False]\n",
    "freq_percent_df2 = freq_percent_df.copy(deep=True)\n",
    "\n",
    "\n",
    "#get the x and y values\n",
    "x = freq_percent_df2.iloc[:, 0 : 255].values\n",
    "y = freq_percent_df2['race']\n",
    "\n",
    "#Black or other setup\n",
    "y.replace({'asian': 0, 'black': 1, 'hispanic': 0, 'white':0}, inplace=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.1)\n",
    "\n",
    "# Converting the type to 'float'\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using keras_tuner to Derive Best FFN\n",
    "https://keras.io/guides/keras_tuner/getting_started/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = 1 #number of races\n",
    "\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=hp.Int(\"units_0\", min_value=512, max_value=1024, step=2), input_shape=(255,)))\n",
    "        for i in range(hp.Int(\"num_layers\", 0, 2)):\n",
    "            model.add(Dense(units=hp.Int(\"units_1\", min_value=512, max_value=2048, step=3)))\n",
    "            model.add(Activation(hp.Choice(\"activation_1\", [\"relu\", \"tanh\", \"sigmoid\"])))\n",
    "        for i in range(hp.Int(\"num_layers2\", 0, 2)):\n",
    "            model.add(Dense(units=hp.Int(\"units_2\", min_value=512, max_value=2048, step=3)))\n",
    "            model.add(Activation(hp.Choice(\"activation_2\", [\"relu\", \"tanh\", \"sigmoid\"])))\n",
    "        if hp.Boolean(\"dropout\"):\n",
    "            model.add(Dropout(hp.Float(\"dropout_val\", min_value=0.01, max_value=0.25, step=4)))\n",
    "        if hp.Boolean(\"regularizer\"):\n",
    "            model.add(Dense(hp.Int(\"units_2\", min_value=512, max_value=2048, step=3), kernel_regularizer=l2(hp.Float(\"regularizer_int\", min_value=0.0001, max_value=0.1, step=4))))\n",
    "        if hp.Boolean(\"batch_norm\"):\n",
    "            model.add(BatchNormalization())\n",
    "        if hp.Boolean(\"next_to_last_activation\"):\n",
    "            model.add(Activation(hp.Choice(\"activation_nlt\", [\"relu\", \"tanh\",\"sigmoid\"])))\n",
    "        if hp.Boolean(\"next_to_last_dense\"):\n",
    "            model.add(Dense(units=hp.Int(\"units_ntl\", min_value=256, max_value=2048, step=4)))\n",
    "        model.add(Dense(outputs, activation='sigmoid'))\n",
    "        \n",
    "        optimizer = Adam(\n",
    "            learning_rate=0.0001,\n",
    "            beta_1=0.9,\n",
    "            beta_2=0.999,\n",
    "            epsilon=1e-07,\n",
    "            amsgrad=True\n",
    "            )\n",
    "        \n",
    "        model.compile(optimizer=optimizer, \n",
    "                      loss='binary_crossentropy', \n",
    "                      metrics=['accuracy', 'AUC'])\n",
    "        return model\n",
    "    \n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            shuffle=hp.Boolean(\"shuffle\"),\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history_ffn = model_ffn.fit(x=x_train,y=y_train, epochs=160,validation_split=0.05, batch_size=1024, shuffle=True)\n",
    "\n",
    "hp = kt.HyperParameters()\n",
    "hypermodel = MyHyperModel()\n",
    "model = hypermodel.build(hp)\n",
    "hypermodel.fit(hp, model, x=x_train,y=y_train, epochs=120,validation_split=0.2, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    MyHyperModel(),\n",
    "    objective=kt.Objective(\"val_auc\", direction=\"max\"),\n",
    "    max_trials=100,\n",
    "    overwrite=False,\n",
    "    directory='models_bva',\n",
    "    project_name='H518_final_bva'\n",
    ")\n",
    "\n",
    "#tuner.search(x=x_train, y=y_train, validation_split=0.2, epochs=60, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "best_model.build()\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate(x=x_test, y=y_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = 1 #number of races\n",
    "hidden_size = 1024\n",
    "hidden_size2 = 2048\n",
    "hidden_size3 = 4096\n",
    "\n",
    "model_ffn = Sequential()\n",
    "model_ffn.add(Dense(hidden_size, input_shape=(255,)))\n",
    "model_ffn.add(Dense(hidden_size))\n",
    "model_ffn.add(Activation('relu'))\n",
    "model_ffn.add(Dense(hidden_size))\n",
    "model_ffn.add(Activation('relu'))\n",
    "model_ffn.add(Dense(hidden_size))\n",
    "model_ffn.add(Activation('tanh'))\n",
    "model_ffn.add(Dropout(0.01))\n",
    "model_ffn.add(Dense(hidden_size, kernel_regularizer=l2(0.0001)))\n",
    "model_ffn.add(Dense(outputs, activation='sigmoid'))\n",
    "\n",
    "\n",
    "optimizer = Adam(\n",
    "    learning_rate=0.0001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    #amsgrad=True\n",
    "    )\n",
    "\n",
    "#binary_crossentropy for binary\n",
    "model_ffn.compile(optimizer=optimizer, \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy', 'AUC'])\n",
    "\n",
    "model_ffn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_ffn = model_ffn.fit(x=x_train,y=y_train, epochs=100,validation_split=0.2, batch_size=4096, shuffle=True)\n",
    "\n",
    "model_ffn.evaluate(x=x_test, y=y_test, return_dict=True)\n",
    "\n",
    "preds0 = model_ffn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, preds)\n",
    "auc_calc = auc(fpr, tpr)\n",
    "auc_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='Binary (area = {:.3f})'.format(auc_calc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"race\"\n",
    "classes = freq_percent_df2[label].unique().tolist()\n",
    "print(f\"Label classes: {classes}\")\n",
    "\n",
    "freq_percent_df2[label] = freq_percent_df2[label].map(classes.index)\n",
    "\n",
    "def split_dataset(dataset, test_ratio=0.10):\n",
    "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
    "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "  return dataset[~test_indices], dataset[test_indices]\n",
    "\n",
    "\n",
    "train_ds_pd, test_ds_pd = split_dataset(freq_percent_df2)\n",
    "print(\"{} examples in training, {} examples for testing.\".format(\n",
    "    len(train_ds_pd), len(test_ds_pd)))\n",
    "\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label)\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing 3 models in one run\n",
    "#RandomForestModel\n",
    "model_1 = tfdf.keras.RandomForestModel(hyperparameter_template=\"benchmark_rank1\")\n",
    "#GradientBoostedTreesModel\n",
    "model_2 = tfdf.keras.GradientBoostedTreesModel(hyperparameter_template=\"benchmark_rank1\")\n",
    "#CartModel\n",
    "model_3 = tfdf.keras.CartModel()\n",
    "\n",
    "# Optionally, add evaluation metrics.\n",
    "model_1.compile(\n",
    "    metrics=[\"AUC\", \"accuracy\"])\n",
    "model_2.compile(\n",
    "    metrics=[\"AUC\", \"accuracy\"])\n",
    "model_3.compile(\n",
    "    metrics=[\"AUC\", \"accuracy\"])\n",
    "\n",
    "# Train the model.\n",
    "# \"sys_pipes\" is optional. It enables the display of the training logs.\n",
    "with sys_pipes():\n",
    "    model_1.fit(x=train_ds)\n",
    "    model_2.fit(x=train_ds)\n",
    "    model_3.fit(x=train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation1 = model_1.evaluate(test_ds, return_dict=True)\n",
    "print()\n",
    "\n",
    "for name, value in evaluation1.items():\n",
    "  print(f\"Random Forest: {name}: {value:.4f}\")\n",
    "\n",
    "evaluation2 = model_2.evaluate(test_ds, return_dict=True)\n",
    "print()\n",
    "\n",
    "for name, value in evaluation2.items():\n",
    "  print(f\"GradientBoostedTreesModel: {name}: {value:.4f}\")\n",
    "\n",
    "evaluation3 = model_3.evaluate(test_ds, return_dict=True)\n",
    "print()\n",
    "\n",
    "for name, value in evaluation3.items():\n",
    "  print(f\"CartModel: {name}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
